{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(np.uint8)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 1000  \n",
    "indices = np.random.choice(len(X), subset_size, replace=False)\n",
    "X_subset = X.iloc[indices]\n",
    "y_subset = y.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=1/7, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize the SVM classifier\n",
    "svm_clf = LinearSVC(max_iter=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the classifier\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 6: Make predictions on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvm_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py:333\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "# Step 6: Make predictions on the test set\n",
    "y_pred = svm_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Evaluate the classifier\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Overall Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find indices of misclassified samples\n",
    "misclassified_indices = np.where(y_test != y_pred)[0]\n",
    "\n",
    "# Plot some misclassified samples\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i, index in enumerate(misclassified_indices[:5]):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_test[index].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"True: {y_test[index]}\\nPred: {y_pred[index]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(np.uint8) \n",
    "\n",
    "subset_size = 1000 \n",
    "indices = np.random.choice(len(X), subset_size, replace=False)\n",
    "X = X.iloc[indices]\n",
    "y = y.iloc[indices]\n",
    "\n",
    "# Scale the features to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_linear = {\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "param_grid_poly = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'degree': [2, 3],\n",
    "    'coef0': [0, 1],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Grid Search for Linear Kernel...\")\n",
    "grid_search_linear = GridSearchCV(\n",
    "    estimator=SVC(kernel='linear'),\n",
    "    param_grid=param_grid_linear,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_linear.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Linear Kernel Grid Search took {end_time - start_time:.2f} seconds.\")\n",
    "print(\"Best Parameters for Linear Kernel:\", grid_search_linear.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_linear.best_score_:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Grid Search for Polynomial Kernel...\")\n",
    "grid_search_poly = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=param_grid_poly,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_poly.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Polynomial Kernel Grid Search took {end_time - start_time:.2f} seconds.\")\n",
    "print(\"Best Parameters for Polynomial Kernel:\", grid_search_poly.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_poly.best_score_:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Grid Search for RBF Kernel...\")\n",
    "grid_search_rbf = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=param_grid_rbf,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_rbf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"RBF Kernel Grid Search took {end_time - start_time:.2f} seconds.\")\n",
    "print(\"Best Parameters for RBF Kernel:\", grid_search_rbf.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_rbf.best_score_:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store evaluation metrics\n",
    "kernel_results = {}\n",
    "\n",
    "# Linear Kernel Evaluation\n",
    "best_linear_clf = grid_search_linear.best_estimator_\n",
    "y_pred_linear = best_linear_clf.predict(X_test)\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "report_linear = classification_report(y_test, y_pred_linear, output_dict=True)\n",
    "kernel_results['linear'] = {\n",
    "    'accuracy': accuracy_linear,\n",
    "    'report': report_linear,\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred_linear)\n",
    "}\n",
    "\n",
    "# Polynomial Kernel Evaluation\n",
    "best_poly_clf = grid_search_poly.best_estimator_\n",
    "y_pred_poly = best_poly_clf.predict(X_test)\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "report_poly = classification_report(y_test, y_pred_poly, output_dict=True)\n",
    "kernel_results['poly'] = {\n",
    "    'accuracy': accuracy_poly,\n",
    "    'report': report_poly,\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred_poly)\n",
    "}\n",
    "\n",
    "# RBF Kernel Evaluation\n",
    "best_rbf_clf = grid_search_rbf.best_estimator_\n",
    "y_pred_rbf = best_rbf_clf.predict(X_test)\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "report_rbf = classification_report(y_test, y_pred_rbf, output_dict=True)\n",
    "kernel_results['rbf'] = {\n",
    "    'accuracy': accuracy_rbf,\n",
    "    'report': report_rbf,\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_pred_rbf)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare perfomance of different kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Set Accuracy for Different Kernels:\")\n",
    "for kernel in kernel_results:\n",
    "    print(f\"{kernel.capitalize()} Kernel Accuracy: {kernel_results[kernel]['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in kernel_results:\n",
    "    print(f\"\\nClassification Report for {kernel.capitalize()} Kernel:\")\n",
    "    print(classification_report(y_test, globals()[f'y_pred_{kernel}']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for kernel in kernel_results:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        kernel_results[kernel]['confusion_matrix'],\n",
    "        annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=np.unique(y), yticklabels=np.unique(y)\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix for {kernel.capitalize()} Kernel\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the kernel with the highest accuracy\n",
    "best_kernel = max(kernel_results, key=lambda k: kernel_results[k]['accuracy'])\n",
    "print(f\"\\nThe best kernel is: {best_kernel.capitalize()} Kernel with accuracy {kernel_results[best_kernel]['accuracy']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
